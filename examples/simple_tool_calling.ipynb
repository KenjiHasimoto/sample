{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "sys.path.append('../../aisuite')\n",
    "\n",
    "# Load from .env file if available\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "from aisuite import ToolManager  # Import your ToolManager class\n",
    "\n",
    "client = ai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock tool functions.\n",
    "def get_current_temperature(location: str, unit: str):\n",
    "    # Simulate fetching temperature from an API\n",
    "    return {\"location\": location, \"unit\": unit, \"temperature\": 72}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"anthropic:claude-3-5-sonnet-20240620\"\n",
    "# model = \"openai:gpt-4o\"\n",
    "# model = mistral:mistral-large-latest\n",
    "# model = \"aws:anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "# model = \"aws:meta.llama3-1-8b-instruct-v1:0\"\n",
    "# model = \"aws:meta.llama3-3-70b-instruct-v1:0\"\n",
    "# model = \"groq:llama-3.1-70b-versatile\"\n",
    "\n",
    "\n",
    "tool_manager = ToolManager([get_current_temperature])\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the current temperature in San Francisco in Celsius?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model, messages=messages, tools=tool_manager.tools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'To answer your question about the current temperature in San '\n",
      "            \"Francisco in Celsius, I'll need to use the available tool to get \"\n",
      "            'that information. Let me fetch that for you.',\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [ChatCompletionMessageToolCall(id='toolu_01SVEv2QJ7tsUatecDD2TEq7', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function')]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the function results, the current temperature in San Francisco is 72 degrees Celsius.\n",
      "\n",
      "It's worth noting that this temperature seems unusually high for San Francisco, as 72째C is equivalent to about 161.6째F, which would be extremely hot for any city. Typically, San Francisco experiences much milder temperatures. This result might be due to an error in the data or the conversion process. \n",
      "\n",
      "To give you a more realistic perspective, San Francisco usually has moderate temperatures year-round, with average highs rarely exceeding 21째C (70째F) even in the warmest months. If you're planning a trip or need accurate current weather information, I'd recommend double-checking this data with a reliable weather service or asking for a verification of the temperature reading.\n"
     ]
    }
   ],
   "source": [
    "if response.choices[0].message.tool_calls:\n",
    "    tool_results, result_as_message = tool_manager.execute_tool(response.choices[0].message.tool_calls)\n",
    "    messages.append(response.choices[0].message) # Model's function call message\n",
    "    messages.append(result_as_message[0])\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=model, messages=messages, tools=tool_manager.tools())\n",
    "    print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, test without tool calling, to check that the normal path is not broken.\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of California?\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=model, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
